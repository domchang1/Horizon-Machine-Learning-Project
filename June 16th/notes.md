Goals:
    -https://jamanetwork.com/journals/jama/fullarticle/2588763 read and try to get hold of networks
        -The specific neural network used in this work is the Inception-v3 architecture
        -For algorithm training, input images were scale normalized by detecting the circular mask of the fundus image and
        resizing the diameter of the fundus to be 299 pixels wide. Images for which the circular mask could not be detected were excluded from the development and the clinical validation sets.
        -optimization algorithm used to train the network weights was a distributed stochastic gradient descent implementation https://proceedings.neurips.cc/paper/2012/hash/6aca97005c68f1206823815f66102863-Abstract.html
        -batch normalization as well as preinitialization using weights from the same network trained to classify objects in the ImageNet data set were used
        -A single network was trained to make multiple binary predictions, including whether the image was (1) moderate or worse diabetic retinopathy (ie, moderate, severe, or proliferative), (2) severe or worse diabetic retinopathy, (3) referable diabetic macular edema, or (4) fully gradable.
        -performance of the algorithm was measured by the area under the receiver operating curve (AUC) generated by plotting sensitivity vs 1 âˆ’ specificity
        -The development set was divided into 2 parts: (1) training: 80% of the data was used to optimize the network weights and (2) tuning: 20% of the data was used to optimize hyperparameters (such as early stopping for training, image preprocessing options).
    -what other ppl's code may be useful for
    -read about SGD and make questions (https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31)
        -gradient descent: descending slope to reach lowest point
            -start w random point, then update gradient function with different parameters, step size = gradient * learning rate, go until gradient almost 0
            -learning rate: large means might miss, gradient descent has big steps when far away
        -SGD: randomly picks one data point from the whole data set at each iteration to reduce the computations enormously
        -Is SGD just a faster but less accurate gradient descent because it skips over almost all of the data?

    -ask any questions
        -How many images should I get the final features for and how do I get those from each image?
        -How do I load my own data and create a dataset and then match it with the labels?
    -resnet
    -figure out how to take last layer off of resnet, get final 512 features for each image and save as file (pytorch/np.save)
        -need preprocessing, make images all the same size (256x256)
        -naming of folders has to be consistent
        -get resnet on the gpu
            -https://www.kaggle.com/code/mishki/resnet-keras-code-from-scratch-train-on-gpu/notebook
    -learn scikit learn and etc., figure how to transform features into labels or scores
    -look at color correction and normalization before running (value ranges for resnet)
        -https://pytorch.org/vision/stable/transforms.html

 What was Acheived:
    -


Needs to be done:
 

Questions:
